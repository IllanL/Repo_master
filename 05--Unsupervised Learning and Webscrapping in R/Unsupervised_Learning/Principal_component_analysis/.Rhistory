carsClusters <- cutree(carsHC, k = 3)
# draw dendogram with red borders around the 3 clusters
plot(carsHC)
rect.hclust(carsHC, k=3, border="red")
# add cluster to data frame of scores
carsDf <- data.frame(pcaCars$scores, "cluster" = factor(carsClusters))
str(carsDf)
ggplot(carsDf,aes(x=Comp.1, y=Comp.2)) +
geom_text_repel(aes(label = rownames(carsDf))) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = cluster), alpha = 0.55, size = 3) +
xlab("PC1") +
ylab("PC2") +
xlim(-5, 6) +
ggtitle("PCA plot of Cars")
rm(list=ls())
knitr::kable(mtcars)
rm(list=ls())
knitr::kable(mtcars)
summary(mtcars)
# cor = TRUE indicates that PCA is performed on
# standardized data (mean = 0, variance= 1)
pcaCars <- princomp(mtcars, cor = TRUE)
# view objects stored in pcaCars
names(pcaCars)
# proportion of variance explained
summary(pcaCars)
# bar plot
plot(pcaCars)
# scree plot
plot(pcaCars, type = "l")
# cluster cars
carsHC <- hclust(dist(pcaCars$scores), method = "ward.D2")
# dendrogram
plot(carsHC)
# cut the dendrogram into 3 clusters
carsClusters <- cutree(carsHC, k = 3)
# draw dendogram with red borders around the 3 clusters
plot(carsHC)
rect.hclust(carsHC, k=3, border="red")
# add cluster to data frame of scores
carsDf <- data.frame(pcaCars$scores, "cluster" = factor(carsClusters))
str(carsDf)
ggplot(carsDf,aes(x=Comp.1, y=Comp.2)) +
geom_text_repel(aes(label = rownames(carsDf))) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = cluster), alpha = 0.55, size = 3) +
xlab("PC1") +
ylab("PC2") +
xlim(-5, 6) +
ggtitle("PCA plot of Cars")
pcaCars$scores
head(pcaCars$score)
pcaCars$score$Comp.1
as.data.frame(pcaCars$score)$Comp.1
my_data<-as.data.frame(pcaCars$score)[,1:2]
names(my_data)<-c("pca1","pca2")
head(my_data)
kmeans(my_data,centers=2,nstart=10)
my_kmeans<-kmeans(my_data,centers=2,nstart=10)
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 2")
if (!require("gridExtra")){install.packages("gridExtra",quiet = T) ; library("gridExtra")}
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 2")
?fviz_cluster
??fviz_cluster
if (!require("factoextra")){install.packages("factoextra",quiet = T) ; library("factoextra")} # clustering algorithms & visualization
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 2")
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 2")
plot(my_data$pca1,my_data$pca2)
a
if (!require("plotly")){install.packages("plotly",quiet = T) ; library("plotly")} # clustering algorithms & visualization
plotl(my_data$pca1,my_data$pca2)
plotl(my_data$pca1,my_data$pca2)
plot_ly(my_data,type = "scatter")
plot_ly(my_data, x=~pca1,y=~pca2,type = "scatter")
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 3")
plot_ly(my_data, x=~pca1,y=~pca2,type = "scatter")
my_kmeans$cluster
ncol(my_data)
nriw(my_data)
nrow(my_data)
length(my_kmeans$cluster)
plot_ly(my_data, x=~pca1,y=~pca2,type = "scatter",color = my_kmeans$centers,colors="Set1")
plot_ly(my_data, x=~pca1,y=~pca2,type = "scatter",color = factor(my_kmeans$centers),colors="Set1")
my_data$clusters<-factor(my_kmeans$centers)
my_kmeans$centers
my_data<-as.data.frame(pcaCars$score)[,1:2]
names(my_data)<-c("pca1","pca2")
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
my_data$clusters<-factor(my_kmeans$centers)
my_kmeans$centers)
my_kmeans$centers
my_data<-as.data.frame(pcaCars$score)[,1:2]
names(my_data)<-c("pca1","pca2")
plot_ly(my_data, x=~pca1,y=~pca2,type = "scatter",color = factor(my_kmeans$cluster),colors="Set1")
?add_markers
my_data<-as.data.frame(pcaCars$score)[,1:3]
names(my_data)<-c("pca1","pca2","pca3")
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 3")
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,type = "scatter",color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers(p = )
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,type = "scatter",color = factor(my_kmeans$cluster),colors="Set1")
my_data
my_data<-as.data.frame(pcaCars$score)[,1:3]
names(my_data)<-c("pca1","pca2","pca3")
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,type = "scatter",color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
my_data
head(my_data)
mtcars$am[which(mtcars$am == 0)] <- 'Automatic'
mtcars$am[which(mtcars$am == 1)] <- 'Manual'
mtcars$am <- as.factor(mtcars$am)
p <- plot_ly(mtcars, x = ~wt, y = ~hp, z = ~qsec, color = ~am, colors = c('#BF382A', '#0C4B8E')) %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
p
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'Weight'),
yaxis = list(title = 'Gross horsepower'),
zaxis = list(title = '1/4 mile time')))
my_data<-as.data.frame(pcaCars$score)[,1:3]
names(my_data)<-c("pca1","pca2","pca3")
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'PC1'),
yaxis = list(title = 'PC2'),
zaxis = list(title = 'PC3')))
my_data$cluster<-my_kmeans$cluster
my_data[which(my_data$cluster==1),]
my_data[which(my_data$cluster==2),]
my_data[which(my_data$cluster==3),]
my_data[which(my_data$cluster==2),]
my_data[which(my_data$cluster==3),]
plot(pcaCars)
plot(pcaCars$scores)
plot(as.data.frame(pcaCars$scores))
plot(as.data.frame(pcaCars$scores[,1:4]))
plot(as.data.frame(pcaCars$scores[,5:9]))
# proportion of variance explained
summary(pcaCars)
# proporcion de varianza explicada por cada componente
summary(pcaCars)
# "score" contiene las componentes principales
pcaCars$scores
# proporcion de varianza explicada por cada componente
summary(pcaCars)
# bar plot
plot(pcaCars)
# scree plot
plot(pcaCars, type = "l")
# cluster cars
carsHC <- hclust(dist(pcaCars$scores), method = "ward.D2")
# dendrogram
plot(carsHC)
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2")
# dendrogram
plot(carsHC)
pcaCars$scores[,1:2]
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2")
# dendrogram
plot(carsHC)
# cluster cars
carsHC <- hclust(dist(pcaCars$scores), method = "ward.D2")
# dendrogram
plot(carsHC)
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2")
# dendrogram
plot(carsHC)
# cut the dendrogram into 3 clusters
carsClusters <- cutree(carsHC, k = 3)
# draw dendogram with red borders around the 3 clusters
plot(carsHC)
rect.hclust(carsHC, k=3, border="red")
# add cluster to data frame of scores
carsDf <- data.frame(pcaCars$scores, "cluster" = factor(carsClusters))
str(carsDf)
carsDf
carsDF
carsDf[which(carsDf$cluster==1),]
carsDf[which(carsDf$cluster==1)2]
carsDf[which(carsDf$cluster==2),]
carsDf[which(carsDf$cluster==3),]
ggplot(carsDf,aes(x=Comp.1, y=Comp.2)) +
geom_text_repel(aes(label = rownames(carsDf))) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = cluster), alpha = 0.55, size = 3) +
xlab("PC1") +
ylab("PC2") +
xlim(-5, 6) +
ggtitle("PCA plot of Cars")
my_data<-as.data.frame(pcaCars$score)[,1:2]
names(my_data)<-c("pca1","pca2")
rm(list=ls())
#Otra manera de importar el dataset
knitr::kable(mtcars)
# Siempre es bueno echarle un vistazo al dataset
summary(mtcars)
# cor = TRUE indica que PCA se realiza en datos estandarizados (media = 0, varianza = 1)
pcaCars <- princomp(mtcars, cor = TRUE)
# que objetos tenemos en pcaCars
names(pcaCars)
# "score" contiene las componentes principales
pcaCars$scores
# proporcion de varianza explicada por cada componente
summary(pcaCars)
# bar plot
plot(pcaCars)
# line plot
plot(pcaCars, type = "l")
#---------------------- Clustering ------------------------#
#Empezamos la parte que nos interesa, como podemos construir un clustering con solo dos variables?
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2")
# dendrogram
plot(carsHC)
# cut the dendrogram into 3 clusters
carsClusters <- cutree(carsHC, k = 3)
# Visualizamos el dendograma con los rectangulos de cada cluster
plot(carsHC)
rect.hclust(carsHC, k=3, border="red")
# anadimos la etiqueta de cluster
carsDf <- data.frame(pcaCars$scores, "cluster" = factor(carsClusters))
str(carsDf)
# Visualizar es siempre la mejor herramienta
ggplot(carsDf,aes(x=Comp.1, y=Comp.2)) +
geom_text_repel(aes(label = rownames(carsDf))) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = cluster), alpha = 0.55, size = 3) +
xlab("PC1") +
ylab("PC2") +
xlim(-5, 6) +
ggtitle("PCA plot of Cars")
#Realice el mismo analisis considerando lo siguiente:
# cluster cars
carsHC <- hclust(dist(pcaCars$scores), method = "ward.D2")
# dendrograma
plot(carsHC)
#--------------------- Ahora con K-means ------------------------------#
#considerando el mismo PCA, exraemos las dos primeras componentes
my_data<-as.data.frame(pcaCars$score)[,1:2]
names(my_data)<-c("pca1","pca2")
# "entrenamos" el kmenas
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
# Visualizar siempre sera de gran ayuda
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 3")
# Ahora con plotly, mas chulo :)
plot_ly(my_data, x=~pca1,y=~pca2,type = "scatter",color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers(p = )
#------------ que ocurre en 3 dimensiones? ---------------------#
#seleccionamos las tres primeras componentes
my_data<-as.data.frame(pcaCars$score)[,1:3]
names(my_data)<-c("pca1","pca2","pca3")
# "entrenamos" el kmeans
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
#Visualizamos con plotly
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers() %>%
layout(scene = list(xaxis = list(title = 'PC1'),
yaxis = list(title = 'PC2'),
zaxis = list(title = 'PC3')))
#Visualizamos con plotly
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers() %>%
plotly::layout(scene = list(xaxis = list(title = 'PC1'),
yaxis = list(title = 'PC2'),
zaxis = list(title = 'PC3')))
rm(list=ls())
#Otra manera de importar el dataset
knitr::kable(mtcars)
# Siempre es bueno echarle un vistazo al dataset
summary(mtcars)
?princomp
rm(list=ls())
#Otra manera de importar el dataset
knitr::kable(mtcars)
# Siempre es bueno echarle un vistazo al dataset
summary(mtcars)
rm(list=ls())
rm(list=ls())
rm(list=ls())
#Otra manera de importar el dataset
knitr::kable(mtcars)
# Siempre es bueno echarle un vistazo al dataset
summary(mtcars)
# cor = TRUE indica si debe realizarse con matriz de correlacion o matriz de covarianzas.
pcaCars <- princomp(mtcars, cor = TRUE)
# que objetos tenemos en pcaCars
names(pcaCars)
# "score" contiene las componentes principales
pcaCars$scores
# proporcion de varianza explicada por cada componente
summary(pcaCars)
# bar plot
plot(pcaCars)
?hclust
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2") #ward.D2: https://es.wikipedia.org/wiki/M%C3%A9todo_de_Ward
carsHC
#---------------------------------------------------------------------------------------------------#
#  ___           _          _                 ____     ____      _
# |_ _|  _ __   (_)   ___  (_)   ___    _    |  _ \   / ___|    / \
#  | |  | '_ \  | |  / __| | |  / _ \  (_)   | |_) | | |       / _ \
#  | |  | | | | | | | (__  | | | (_) |  _    |  __/  | |___   / ___ \
# |___| |_| |_| |_|  \___| |_|  \___/  (_)   |_|      \____| /_/   \_\
#
#---------------------------------------------------------------------------------------------------#
# Este codigo es utilizado para explicar como funciona el Analisis de componentes principales
# para reducir la dimensionalidad del dataset y aplicar clustering.
#---------------------------------------------------------------------------------------------------#
rm(list=ls())
#Otra manera de importar el dataset
knitr::kable(mtcars)
# Siempre es bueno echarle un vistazo al dataset
summary(mtcars)
# cor = TRUE indica si debe realizarse con matriz de correlacion o matriz de covarianzas.
pcaCars <- princomp(mtcars, cor = TRUE)
# que objetos tenemos en pcaCars
names(pcaCars)
# "score" contiene las componentes principales
pcaCars$scores
# proporcion de varianza explicada por cada componente
summary(pcaCars)
# bar plot
plot(pcaCars)
# line plot
plot(pcaCars, type = "l")
#---------------------- Clustering ------------------------#
#Empezamos la parte que nos interesa, como podemos construir un clustering con solo dos variables?
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2") #ward.D2: https://es.wikipedia.org/wiki/M%C3%A9todo_de_Ward
# dendrogram
plot(carsHC)
# Visualizamos el dendograma con los rectangulos de cada cluster
plot(carsHC)
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2") #ward.D2: https://es.wikipedia.org/wiki/M%C3%A9todo_de_Ward
# dendrogram
plot(carsHC)
# cut the dendrogram into 3 clusters
carsClusters <- cutree(carsHC, k = 3)
# Visualizamos el dendograma con los rectangulos de cada cluster
plot(carsHC)
rect.hclust(carsHC, k=3, border="red")
# anadimos la etiqueta de cluster
carsDf <- data.frame(pcaCars$scores, "cluster" = factor(carsClusters))
carsDf
# Visualizamos el dendograma con los rectangulos de cada cluster
plot(carsHC)
rect.hclust(carsHC, k=3, border="red")
# anadimos la etiqueta de cluster
carsDf <- data.frame(pcaCars$scores, "cluster" = factor(carsClusters))
carsDf
# Visualizar es siempre la mejor herramienta
ggplot(carsDf,aes(x=Comp.1, y=Comp.2)) +
geom_text_repel(aes(label = rownames(carsDf))) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = cluster), size = 3) +
xlab("PC1") +
ylab("PC2") +
xlim(-5, 6) +
ggtitle("PCA plot of Cars")
#Realice el mismo analisis considerando todas las componentes principales:
# cluster cars
carsHC <- hclust(dist(pcaCars$scores), method = "ward.D2")
# dendrograma
plot(carsHC)
# Visualizar siempre sera de gran ayuda
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 3")
#considerando el mismo PCA, exraemos las dos primeras componentes
my_data<-as.data.frame(pcaCars$score)[,1:2]
names(my_data)<-c("pca1","pca2")
#seleccionamos las tres primeras componentes
my_data<-as.data.frame(pcaCars$score)[,1:3]
names(my_data)<-c("pca1","pca2","pca3")
#---------------------------------------------------------------------------------------------------#
#  ___           _          _                 ____     ____      _
# |_ _|  _ __   (_)   ___  (_)   ___    _    |  _ \   / ___|    / \
#  | |  | '_ \  | |  / __| | |  / _ \  (_)   | |_) | | |       / _ \
#  | |  | | | | | | | (__  | | | (_) |  _    |  __/  | |___   / ___ \
# |___| |_| |_| |_|  \___| |_|  \___/  (_)   |_|      \____| /_/   \_\
#
#---------------------------------------------------------------------------------------------------#
# Este codigo es utilizado para explicar como funciona el Analisis de componentes principales
# para reducir la dimensionalidad del dataset y aplicar clustering.
#---------------------------------------------------------------------------------------------------#
rm(list=ls())
#Otra manera de importar el dataset
knitr::kable(mtcars)
# Siempre es bueno echarle un vistazo al dataset
summary(mtcars)
# cor = TRUE indica si debe realizarse con matriz de correlacion o matriz de covarianzas.
pcaCars <- princomp(mtcars, cor = TRUE)
# que objetos tenemos en pcaCars
names(pcaCars)
# "score" contiene las componentes principales
pcaCars$scores
# proporcion de varianza explicada por cada componente
summary(pcaCars)
# bar plot
plot(pcaCars)
# line plot
plot(pcaCars, type = "l")
#---------------------- Clustering ------------------------#
#Empezamos la parte que nos interesa, como podemos construir un clustering con solo dos variables?
# cluster cars
carsHC <- hclust(dist(pcaCars$scores[,1:2]), method = "ward.D2") #ward.D2: https://es.wikipedia.org/wiki/M%C3%A9todo_de_Ward
# dendrogram
plot(carsHC)
# cut the dendrogram into 3 clusters
carsClusters <- cutree(carsHC, k = 3)
# Visualizamos el dendograma con los rectangulos de cada cluster
plot(carsHC)
rect.hclust(carsHC, k=3, border="red")
# anadimos la etiqueta de cluster
carsDf <- data.frame(pcaCars$scores, "cluster" = factor(carsClusters))
carsDf
# Visualizar es siempre la mejor herramienta
ggplot(carsDf,aes(x=Comp.1, y=Comp.2)) +
geom_text_repel(aes(label = rownames(carsDf))) +
theme_classic() +
geom_hline(yintercept = 0, color = "gray70") +
geom_vline(xintercept = 0, color = "gray70") +
geom_point(aes(color = cluster), size = 3) +
xlab("PC1") +
ylab("PC2") +
xlim(-5, 6) +
ggtitle("PCA plot of Cars")
#Realice el mismo analisis considerando todas las componentes principales:
# cluster cars
carsHC <- hclust(dist(pcaCars$scores), method = "ward.D2")
# dendrograma
plot(carsHC)
#--------------------- Ahora con K-means ------------------------------#
#considerando el mismo PCA, exraemos las dos primeras componentes
my_data<-as.data.frame(pcaCars$score)[,1:2]
names(my_data)<-c("pca1","pca2")
# "entrenamos" el kmenas
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
# Visualizar siempre sera de gran ayuda
fviz_cluster(my_kmeans, geom = "point", data = my_data) + ggtitle("k = 3")
# Ahora con plotly, mas chulo :)
plot_ly(my_data, x=~pca1,y=~pca2,type = "scatter",color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers(p = )
#------------ que ocurre en 3 dimensiones? ---------------------#
#seleccionamos las tres primeras componentes
my_data<-as.data.frame(pcaCars$score)[,1:3]
names(my_data)<-c("pca1","pca2","pca3")
# "entrenamos" el kmeans
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
#Visualizamos con plotly
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers() %>%
plotly::layout(scene = list(xaxis = list(title = 'PC1'),
yaxis = list(title = 'PC2'),
zaxis = list(title = 'PC3')))
# que valores quedaron en cada cluster?
my_data$cluster<-my_kmeans$cluster
my_data[which(my_data$cluster==1),]
if (!require("ggplot2")){install.packages("ggplot2",quiet = T) ; library("ggplot2")}
if (!require("ggrepel")){install.packages("ggrepel",quiet = T) ; library("ggrepel")}
if (!require("factoextra")){install.packages("factoextra",quiet = T) ; library("factoextra")} # clustering algorithms & visualization
if (!require("plotly")){install.packages("plotly",quiet = T) ; library("plotly")}
if (!require("knitr")){install.packages("knitr",quiet = T) ; library("knitr")}
print("All packages and functions have been installed or loaded...")
rm(list=ls())
#Otra manera de importar el dataset
knitr::kable(mtcars)
# Siempre es bueno echarle un vistazo al dataset
summary(mtcars)
# cor = TRUE indica si debe realizarse con matriz de correlacion o matriz de covarianzas.
pcaCars <- princomp(mtcars, cor = TRUE)
pcaCars
?princomp
eigen(mtcars)$values
eigen(cor(mtcars)$values
eigen(cor(mtcars))$values
#seleccionamos las tres primeras componentes
my_data<-as.data.frame(pcaCars$score)[,1:3]
names(my_data)<-c("pca1","pca2","pca3")
# "entrenamos" el kmeans
my_kmeans<-kmeans(my_data,centers=3,nstart=10)
#Visualizamos con plotly
plot_ly(my_data, x=~pca1,y=~pca2,z=~pca3,color = factor(my_kmeans$cluster),colors="Set1") %>%
add_markers() %>%
plotly::layout(scene = list(xaxis = list(title = 'PC1'),
yaxis = list(title = 'PC2'),
zaxis = list(title = 'PC3')))
View(my_data)
mtcars
